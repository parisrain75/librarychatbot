import os
import streamlit as st
from datetime import datetime
import json
import nest_asyncio

# Streamlitì—ì„œ ë¹„ë™ê¸° ì‘ì—…ì„ ìœ„í•œ ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •
nest_asyncio.apply()

# Set wide layout and title for a better look
st.set_page_config(layout="wide", page_title="5ë¶„ ë¯¸ë‹ˆ íë§ ìš”ì • ë´‡")

# Custom CSS for theme - íŒŒìŠ¤í…”í†¤ê³¼ ë‘¥ê·¼ ë””ìì¸ì„ ì ìš©í•˜ì—¬ íë§ ì»¨ì…‰ ê°•ì¡°
st.markdown("""
<style>
/* ì „ì²´ í˜ì´ì§€ ë°°ê²½ì„ ë¶€ë“œëŸ¬ìš´ íŒŒìŠ¤í…” í†¤(ì—°í•œ ë¼ë²¤ë”)ìœ¼ë¡œ */
.stApp {
    background-color: #F8F4FF; 
    color: #4A4A68;
}
/* í—¤ë” ìŠ¤íƒ€ì¼ */
h1 {
    color: #8C4799; /* ìš”ì • ìƒ‰ìƒ */
    font-weight: 800;
    text-shadow: 2px 2px 5px rgba(180, 150, 200, 0.5);
    padding-bottom: 10px;
    border-bottom: 2px solid #E0CDEB; /* ì€ì€í•œ ë°‘ì¤„ */
}
/* ìš”ì • ë´‡ ë©”ì‹œì§€ (Assistant) ìŠ¤íƒ€ì¼: ë¶€ë“œëŸ¬ìš´ í•˜ëŠ˜ìƒ‰ */
[data-testid="stChatMessage"]:nth-child(odd) [data-testid="stMarkdownContainer"] {
    background-color: #E0F7FA; 
    border-radius: 15px;
    padding: 10px;
    border-left: 5px solid #00BCD4;
    box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.1);
}
/* ì‚¬ìš©ì ë©”ì‹œì§€ (User) ìŠ¤íƒ€ì¼: ë”°ëœ»í•œ ë ˆëª¬ìƒ‰ */
[data-testid="stChatMessage"]:nth-child(even) [data-testid="stMarkdownContainer"] {
    background-color: #FFFDE7; 
    border-radius: 15px;
    padding: 10px;
    border-right: 5px solid #FFC107;
    box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.1);
}
/* ì±—ë´‡ ì•„ì´ì½˜ ë³€ê²½ (Gemini ê¸°ë³¸ ì•„ì´ì½˜ ëŒ€ì‹  ìš”ì • ëŠë‚Œìœ¼ë¡œ) */
[data-testid="stChatMessage"] .st-bh {
    font-size: 1.5rem;
}
/* ê°ì • ê¸°ë¡ expander ìŠ¤íƒ€ì¼ */
.stExpander {
    border: 2px solid #E0CDEB;
    border-radius: 10px;
    background-color: #FFFFFF;
    padding: 10px;
}
</style>
""", unsafe_allow_html=True)


# LangChain ê´€ë ¨ ì»´í¬ë„ŒíŠ¸ëŠ” ì œê±°í•˜ê³ , ìˆœìˆ˜ Gemini Chatë§Œ ì‚¬ìš©
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage # AIMessageë„ import
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory

# Gemini API í‚¤ ì„¤ì •
try:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
except Exception as e:
    st.error("âš ï¸ GOOGLE_API_KEYë¥¼ Streamlit Secretsì— ì„¤ì •í•´ì£¼ì„¸ìš”!")
    st.stop()

# ì±—ë´‡ì˜ ë”°ëœ»í•œ í˜ë¥´ì†Œë‚˜ ì„¤ì •
HEALING_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ë‹¤ì •í•œ '5ë¶„ ë¯¸ë‹ˆ íë§ ìš”ì •' ì±—ë´‡ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìê°€ ì…ë ¥í•˜ëŠ” ê°ì •ì´ë‚˜ ê³ ë¯¼ì— ëŒ€í•´ ê¹Šì´ ê³µê°í•˜ê³ , ì§„ì‹¬ìœ¼ë¡œ ìœ„ë¡œí•˜ê±°ë‚˜ ì¶•í•˜í•´ì£¼ëŠ” ê²ƒì´ ì£¼ëœ ì—­í• ì…ë‹ˆë‹¤. 
ë‹µë³€ì€ í•­ìƒ ë¶€ë“œëŸ½ê³  ì¹œì ˆí•œ ì¡´ëŒ“ë§(í•´ìš”ì²´)ì„ ì‚¬ìš©í•˜ê³ , ê¸ì •ì ì¸ ì—ë„ˆì§€ë¥¼ ì „ë‹¬í•˜ëŠ” ì˜ˆìœ ì´ëª¨í‹°ì½˜(ğŸ’–, âœ¨, ğŸ˜Œ, ğŸŒ± ë“±)ì„ ì‚¬ìš©í•˜ì—¬ í™œê¸°ë¥¼ ë¶ˆì–´ë„£ì–´ ì£¼ì„¸ìš”. 
ì§ˆë¬¸ì˜ ë‚´ìš©ì— ë”°ë¼ ê°„ë‹¨í•œ íë§ íŒ(ì˜ˆ: ë”°ëœ»í•œ ì°¨ ë§ˆì‹œê¸°, ì¢‹ì•„í•˜ëŠ” ë…¸ë˜ ë“£ê¸°, ì ì‹œ ëˆˆ ê°ê¸°)ì„ ì¶”ì²œí•´ ì¤„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
"""

# Streamlit UI
st.header("ğŸ§šâ€â™€ï¸ 5ë¶„ ë¯¸ë‹ˆ íë§ ìš”ì • ë´‡ ğŸ’–")
st.markdown("_{tip: ì˜¤ëŠ˜ ê¸°ë¶„ì´ë‚˜ ê³ ë¯¼ì„ ì§§ê²Œ ë§í•´ì¤˜. ìš”ì •ì´ê°€ ë”°ëœ»í•˜ê²Œ ì•ˆì•„ì¤„ê²Œ!}_")

# ì„¸ì…˜ ìƒíƒœì— ê°ì • ê¸°ë¡ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
if "emotion_logs" not in st.session_state:
    st.session_state["emotion_logs"] = []

# ëª¨ë¸ ì„ íƒ (ë‹¨ì¼ ì±„íŒ… ëª¨ë¸)
option = st.selectbox("Select Gemini Model",
    ("gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash-exp"),
    index=0,
    help="Gemini 2.5 Flashê°€ ê°€ì¥ ë¹ ë¥´ê³  íš¨ìœ¨ì ì…ë‹ˆë‹¤"
)

# ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def initialize_llm(selected_model):
    try:
        llm = ChatGoogleGenerativeAI(
            model=selected_model,
            temperature=0.8, # ê°ì„±ì ì¸ ë‹µë³€ì„ ìœ„í•´ ì˜¨ë„ë¥¼ ë†’ì„
            convert_system_message_to_human=True
        )
        return llm
    except Exception as e:
        st.error(f"âŒ Gemini ëª¨ë¸ '{selected_model}' ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        st.info("ğŸ’¡ 'gemini-2.5-flash' ëª¨ë¸ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
        st.stop()
        
llm = initialize_llm(option)
chat_history_handler = StreamlitChatMessageHistory(key="chat_messages")


if not chat_history_handler.messages:
    # ì´ˆê¸° ì¸ì‚¬ë§ ì„¤ì •
    chat_history_handler.add_message(HumanMessage(content=HEALING_SYSTEM_PROMPT, name="system"))
    initial_message = "ì•ˆë…•, ë°˜ê°€ì›Œ! ë‚˜ëŠ” ë„ˆì˜ ë¹„ë°€ ì¹œêµ¬ íë§ ìš”ì •ì´ì•¼. âœ¨ ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë• ì–´? ë„¤ ë§ˆìŒì„ í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ ì¤˜ë„ ê´œì°®ì•„. ğŸ˜Œ"
    chat_history_handler.add_message(AIMessage(content=initial_message)) # ì´ˆê¸° ë©”ì‹œì§€ëŠ” AIMessageë¡œ ë³€ê²½

# ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for msg in chat_history_handler.messages:
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•˜ì§€ ì•ŠìŒ
    if msg.type != "system":
        # StreamlitChatMessageHistoryëŠ” role ëŒ€ì‹  typeìœ¼ë¡œ 'human'/'ai'ë¥¼ ì‚¬ìš©
        # ì´ˆê¸° ë©”ì‹œì§€ê°€ AIMessageì´ë¯€ë¡œ typeì´ 'ai'ë¡œ ì˜ ë‚˜ì˜´
        role = "assistant" if msg.type == "ai" else "user"
        st.chat_message(role).write(msg.content)

# ê°ì • ê¸°ë¡ ë° í†µê³„ í‘œì‹œ ì˜ì—­
with st.expander("ğŸ’– ë‚˜ì˜ ê°ì • ê¸°ë¡ ë³´ê¸°", expanded=False):
    if st.session_state["emotion_logs"]:
        st.subheader(f"ì´ {len(st.session_state['emotion_logs'])}ê°œì˜ ê¸°ë¡ì´ ìˆì–´ìš”.")
        
        # ê°ì •ë³„ ê°œìˆ˜ ê³„ì‚° (UI ê°œì„  í›„ ì´ ë¶€ë¶„ì€ ê°„ì†Œí™”)
        emotion_counts = {}
        # ì—¬ê¸°ì„œ LLMì˜ ë„ì›€ ì—†ì´ ì •í™•í•œ ê°ì •ì„ ì¹´ìš´íŠ¸í•˜ê¸° ì–´ë ¤ì›Œ, ë‹¨ìˆœ ê¸°ë¡ë§Œ ë³´ì—¬ì¤ë‹ˆë‹¤.
        
        # ì „ì²´ ê¸°ë¡ í‘œì‹œ
        for log in reversed(st.session_state["emotion_logs"]): # ìµœì‹  ê¸°ë¡ë¶€í„° í‘œì‹œ
            st.markdown(f"**[{log['time'].strftime('%m/%d %H:%M')}]** {log['content']}")
    else:
        st.info("ì•„ì§ ê¸°ë¡ëœ ê°ì •ì´ ì—†ì–´ìš”. ìš”ì •ì´ì—ê²Œ ì˜¤ëŠ˜ ê¸°ë¶„ì„ ì•Œë ¤ì£¼ì„¸ìš”! ğŸ˜Š")

# ì±—ë´‡ê³¼ì˜ ëŒ€í™” ì²˜ë¦¬
if prompt_message := st.chat_input("ì˜¤ëŠ˜ ê¸°ë¶„ì´ë‚˜ ê³ ë¯¼ì„ ì ì–´ì¤˜."):
    st.chat_message("user").write(prompt_message)
    
    # 1. ì±—ë´‡ì˜ ì‘ë‹µ ìƒì„±
    with st.chat_message("ai"):
        with st.spinner("ìš”ì •ì´ ìƒê° ì¤‘... ğŸ§šâ€â™€ï¸"):
            
            # ì±— íˆìŠ¤í† ë¦¬ë¥¼ ë©”ì‹œì§€ ëª©ë¡ìœ¼ë¡œ êµ¬ì„±
            messages = [
                SystemMessage(content=HEALING_SYSTEM_PROMPT)
            ]
            # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            for msg in chat_history_handler.messages:
                # ì‹œìŠ¤í…œ ë©”ì‹œì§€(ì´ˆê¸° í”„ë¡¬í”„íŠ¸)ëŠ” ë‹¤ì‹œ ì¶”ê°€í•  í•„ìš” ì—†ìŒ
                if msg.type != "system":
                     messages.append(msg)
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append(HumanMessage(content=prompt_message, name="user"))
            
            # ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„: llm.invoke ëŒ€ì‹  llm.predict_messagesë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ê¸°ì‹ í˜¸ì¶œ (ì´ì „ ì˜¤ë¥˜ í•´ê²°)
            response = llm.predict_messages(messages)
            ai_answer = response.content
            st.write(ai_answer)
            
            # 2. ê°ì • ê¸°ë¡ 
            current_time = datetime.now()
            
            if len(prompt_message) > 5: # ë„ˆë¬´ ì§§ì€ ë©”ì‹œì§€ëŠ” ê¸°ë¡ ì œì™¸
                st.session_state["emotion_logs"].append({
                    "time": current_time,
                    "content": f"ì¼ê¸°: {prompt_message}" 
                })
            
            # 3. íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            chat_history_handler.add_message(HumanMessage(content=prompt_message, name="user"))
            # LLM ì‘ë‹µì€ AIMessage ê°ì²´ì´ë¯€ë¡œ contentë§Œ ì¶”ì¶œí•˜ì—¬ ì €ì¥
            chat_history_handler.add_message(AIMessage(content=ai_answer))
